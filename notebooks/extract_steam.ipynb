{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3532e071-281a-4044-a99d-5fb4d4378829",
   "metadata": {},
   "source": [
    "# Description\n",
    "This notebook demonstrates a generic process for transforming XBRL based FERC Form 1 filings to be compatible with historical data. See `README` and `extract_fuel` for notes on setup. This notebook requires the raw `ferc1` database produced by `ferc1_to_sqlite` in `PUDL`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b9272f-a7b5-4b15-901a-0f0bcb4742f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, MetaData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98441721-88e5-4a0b-bc90-fd7ff796a8a6",
   "metadata": {},
   "source": [
    "There needs to be some mapping between table names. This notebook uses the `f1_steam` table for demonstration, but it is meant to be as generic as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d118e-dccf-4994-a8b2-ab774a1e86ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of what table map might look like\n",
    "table_map = {\n",
    "    \"f1_steam\": \"402 - Schedule - Steam-Electric Generating Plant Statistics (Large Plants)\",\n",
    "}\n",
    "\n",
    "# Open old db and db with extracted xbrl data\n",
    "xbrl_db = create_engine(\"sqlite:///ferc1.sqlite\")\n",
    "old_db = create_engine(\"sqlite:///dbf_ferc1.sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b53a1db-a8ee-4326-86bd-6362b139c5cb",
   "metadata": {},
   "source": [
    "Get columns from table in old db and new db to prepare for mapping between columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1be26-88e5-4bd9-9b74-8ad4ea32047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get column names from a table given a sqlalchemy connection and table name\n",
    "def extract_table_cols(engine, table_name):\n",
    "    metadata = MetaData(bind=engine)\n",
    "    metadata.reflect()\n",
    "    return list(metadata.tables[table_name].columns.keys())\n",
    "\n",
    "# Read in XBRL table\n",
    "xbrl_steam = pd.read_sql(\n",
    "    table_map[\"f1_steam\"],\n",
    "    xbrl_db,\n",
    "    parse_dates=[\"start_date\", \"end_date\"]\n",
    ").drop(\"index\", axis=1)\n",
    "\n",
    "old_cols = extract_table_cols(old_db, \"f1_steam\")\n",
    "new_cols = list(xbrl_steam.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d08cd7-fcda-40d1-8e4b-873ab61471ca",
   "metadata": {},
   "source": [
    "Remove Columns with `Axis` suffix. XBRL uses dimensions for indicating the context of facts, and those dimensions are added as columns to the extracted table with the suffix `Axis`. In many cases these columns are essentially repeated, and one of them needs to be removed, because columns are matched based on order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573fce9-8b63-4374-b590-503bac0f71c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_axes(cols):\n",
    "    update_cols = []\n",
    "    for col in cols:\n",
    "        if col.endswith(\"Axis\") and col.rstrip(\"Axis\") in cols:\n",
    "            continue\n",
    "        update_cols.append(col)\n",
    "    return update_cols\n",
    "\n",
    "new_cols = strip_axes(new_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e92822-7ccc-464b-8fd3-860d1a58223e",
   "metadata": {},
   "source": [
    "Attempt to generate a column map based on the column order. This will skip gneric columns included in every table, and footnote columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7025d827-b202-426c-b91d-96dd7bc2c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_col_map(old_cols, new_cols):\n",
    "    default_cols_old = [\"respondent_id\", \"report_year\", \"spplmnt_num\", \"row_number\", \"row_seq\", \"row_prvlg\", \"report_prd\"]\n",
    "    old_cols = [col for col in old_cols if col not in default_cols_old and not col.endswith(\"_f\")]\n",
    "    \n",
    "    default_cols_new = [\"entity_id\", \"start_date\", \"end_date\", \"instant\", \"OrderNumber\"]\n",
    "    new_cols = [col for col in new_cols if col not in default_cols_new]\n",
    "\n",
    "    if len(new_cols) != len(old_cols):\n",
    "        raise Exception(\"Can't generate column map\")\n",
    "\n",
    "    return {old_col: new_col for old_col, new_col in zip(old_cols, new_cols)}\n",
    "\n",
    "col_map = create_col_map(old_cols, new_cols)\n",
    "for key, val in col_map.items():\n",
    "    print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f4f45-a635-46ec-897f-b823ddaaba92",
   "metadata": {},
   "source": [
    "From inspection, this appears to have done a very good job with one important exception. The column `asset_retire_cost` is at the end of the old table, but `AssetRetirementCostsSteamProduction` (which is clearly the equivalent column in the new table) is in the middle. These leads to the rest of the columns all being off by one.\n",
    "\n",
    "Perhaps a better approach would be to use a string similarity metric to attempt to match column names. To do this, I've used [Jaro-Winkler](https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance) distance for computing the metric, and picked mappings that minimize the total string distance across all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffae93d-7189-4165-a741-f81c75fccde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "import stringcase\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# Mapping func using string similarity\n",
    "def create_col_map_similarity(old_cols, new_cols):\n",
    "    default_cols_old = [\"respondent_id\", \"report_year\", \"spplmnt_num\", \"row_number\", \"row_seq\", \"row_prvlg\", \"report_prd\"]\n",
    "    old_cols = [col for col in old_cols if col not in default_cols_old and not col.endswith(\"_f\")]\n",
    "    \n",
    "    default_cols_new = [\"entity_id\", \"start_date\", \"end_date\", \"instant\", \"OrderNumber\"]\n",
    "    new_cols = [col for col in new_cols if col not in default_cols_new]\n",
    "    \n",
    "    similarity_matrix = np.zeros((len(old_cols), len(new_cols)))\n",
    "    for i, old_col in enumerate(old_cols):\n",
    "        for j, new_col in enumerate(new_cols):\n",
    "            # Transform new column names from CamelCase to snake_case and compute similarity matrix between all column names\n",
    "            similarity_matrix[i, j] = jellyfish.jaro_winkler(old_col, stringcase.snakecase(new_col))\n",
    "    \n",
    "    # Find wich mappings minimize (this optimization is a variation of the assignment problem)\n",
    "    row_ind, col_ind = linear_sum_assignment(similarity_matrix, maximize=True)\n",
    "    \n",
    "    return {old_cols[old_ind]: new_cols[new_ind] for old_ind, new_ind in zip(row_ind, col_ind)}\n",
    "\n",
    "col_map_similarity = create_col_map_similarity(old_cols, new_cols)\n",
    "for key, val in col_map_similarity.items():\n",
    "    print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34d97c4-d2ce-4c92-9731-d0e27925ad1d",
   "metadata": {},
   "source": [
    "This approach does properly match `asset_retire_cost`, but it also mismatches many other columns. It's possible that a more sophisticated approach could handle these cases (perhaps one that considers both order, and string similarity, or a string similarity metric that better accounts for the use of abbreviations or words in different orders), but it might also be easier to just manually fix these errors.\n",
    "\n",
    "For now I'll manually move `AssetRetirementCostsSteamProduction` to the correct place and shift the other column names that are off by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf59fe-1088-4293-aa42-8e182b8a3b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(col_map.keys())[16:-1]\n",
    "previous_val = col_map[\"asset_retire_cost\"]\n",
    "\n",
    "for key in reversed(keys):\n",
    "    tmp = col_map[key]\n",
    "    col_map[key] = previous_val\n",
    "    previous_val = tmp\n",
    "    \n",
    "col_map[\"asset_retire_cost\"] = \"AssetRetirementCostsSteamProduction\"\n",
    "print(col_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703fcf23-734d-428b-b126-1f7a30a8c82a",
   "metadata": {},
   "source": [
    "Using this generated column map, assemble the new table composed of XBRL data. The first thing to do is handle the durations in the XBRL data. XBRL uses durations to identify facts. Some facts are reported with an instantaneous duration while others have an actual date range. The historical data does not have this conceptof durations and only provides the report year. The first function here will match rows with an instant duration with rows with a compatible date range. The instant date should line up with the end date according to [this](https://www.ferc.gov/sites/default/files/2020-05/FERC_Taxonomy_Guide.pdf) guide on the FERC taxonomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3062828d-282c-489d-af9d-2d6411525f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_durations(table):\n",
    "    # Seperate facts with instant duration vs normal duration\n",
    "    duration_facts = table.loc[table[\"instant\"] == False, :].drop(\"instant\", axis=1)\n",
    "    instant_facts = table.loc[table[\"instant\"] == True, :].drop(\"instant\", axis=1)\n",
    "    \n",
    "    # Take only columns that have data (this function assumes that this will produce non overlapping sets of columns\n",
    "    duration_facts = duration_facts.loc[:, ~duration_facts.isnull().all(axis=0)]\n",
    "    instant_facts = instant_facts.loc[:, ~instant_facts.isnull().all(axis=0)]\n",
    "    \n",
    "    indices = [\"entity_id\", \"end_date\"] + [col for col in instant_facts.columns if col.endswith(\"Axis\")]\n",
    "    \n",
    "    return duration_facts.join(instant_facts.set_index(indices), on=indices)\n",
    "\n",
    "# Use the generated column map to assemble the table\n",
    "def create_df(table, col_map):\n",
    "    df_dict = {\n",
    "        'respondent_id': table['entity_id'],\n",
    "        'report_year': table['start_date'].dt.year,\n",
    "        'supplmnt_num': np.zeros(len(table), dtype=int),\n",
    "        'row_number': np.zeros(len(table), dtype=int),\n",
    "        'row_seq': np.zeros(len(table), dtype=int),\n",
    "        'row_prvlg': np.zeros(len(table), dtype=int),\n",
    "    }\n",
    "    \n",
    "    df_dict.update({old_col: table[new_col] for old_col, new_col in col_map.items()})\n",
    "    return pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6705d1c-83a2-47b6-8140-70f5ef353cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbrl_steam = process_durations(xbrl_steam)\n",
    "xbrl_steam = create_df(xbrl_steam, col_map)\n",
    "xbrl_steam = xbrl_steam[xbrl_steam[\"report_year\"] == 2011]\n",
    "xbrl_steam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea94478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
